{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Models in Pyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I cannot find documentation for pyro functions, so I will use definition of similiar TensorFlow functions\n",
    "import torch\n",
    "import pyro\n",
    "\n",
    "\n",
    "\n",
    "# Sets the graph-level random seed\n",
    "pyro.set_rng_seed(101)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primitive Stochastic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal(scale: 1.0, loc: 1.0)\n",
      "sample:  tensor(-0.3905)\n",
      "log prob:  tensor(-1.8857)\n"
     ]
    }
   ],
   "source": [
    "# Create a normal distribution and draw a sample from it\n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "# Mean zero\n",
    "loc = 1\n",
    "\n",
    "# Unit variance\n",
    "scale = 1\n",
    "\n",
    "# Create a normal distribution object \n",
    "normal = torch.distributions.Normal(loc, scale)\n",
    "\n",
    "# Draw a sample from N(0,1)\n",
    "x = normal.rsample()\n",
    "\n",
    "print(normal)\n",
    "\n",
    "# Print sample\n",
    "print(\"sample: \",x)\n",
    "\n",
    "# Score the sample from N(0,1)\n",
    "print(\"log prob: \",normal.log_prob(x))\n",
    "# Log probability is simply the logarithm of a probability.\n",
    "# Representing probabilities in this way has several practical advantages, such as speed, accuracy and simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cloudy', 46.847618103027344)\n",
      "('cloudy', 53.20433807373047)\n",
      "('sunny', 91.11004638671875)\n",
      "('cloudy', 52.48044204711914)\n",
      "('sunny', 68.44023895263672)\n",
      "('sunny', 80.18768310546875)\n",
      "('cloudy', 54.89055252075195)\n",
      "('sunny', 42.057411193847656)\n",
      "('cloudy', 52.833702087402344)\n",
      "('sunny', 80.13694763183594)\n"
     ]
    }
   ],
   "source": [
    "# Create a simple stochastic function that describes how temperature interacts with whether it was sunny or cloudy on a day\n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "def weather():\n",
    "    # Create a Bernoulli distribution and sample from it, so our sample is either a 1 or 0\n",
    "    # 0.3 = 30% chance of a 1, and 70% chance of a 0\n",
    "    cloudy = torch.distributions.Bernoulli(0.3).sample()\n",
    "    # If our sample is 1, then we say it was \"cloudy\", else it was \"sunny\"\n",
    "    cloudy = \"cloudy\" if cloudy.item() == 1.0 else \"sunny\"\n",
    "    \n",
    "    # Create a dicstrionary with the sky attributes as keys, and the values are the temperature\n",
    "    # At the same time, we acces a value by reffering to the key [cloudy]. This value is our temperature mean\n",
    "    # Note that cloudy days have a lower mean temperature\n",
    "    mean_temp = {\"cloudy\": 55.0, \"sunny\": 75.0}[cloudy]\n",
    "    \n",
    "    # Same as above, but this is our variance for the temperature\n",
    "    scale_temp = {\"cloudy\": 10.0, \"sunny\": 15.0}[cloudy]\n",
    "    \n",
    "    # Create a normal distribution for the temperature, giving it our mean and variance we calculated above\n",
    "    # We immidently sample from it\n",
    "    temp = torch.distributions.Normal(mean_temp, scale_temp).rsample()\n",
    "    \n",
    "    # Return sky attribute with the temperature\n",
    "    return cloudy, temp.item()\n",
    "    \n",
    "for i in range(0,10):\n",
    "    print(weather())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The pyro.sample Primitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sunny', 76.62906646728516)\n",
      "('cloudy', 42.30691146850586)\n",
      "('sunny', 55.182289123535156)\n",
      "('sunny', 65.34877014160156)\n",
      "('cloudy', 66.43797302246094)\n",
      "('cloudy', 57.695831298828125)\n",
      "('cloudy', 66.84027099609375)\n",
      "('sunny', 66.80554962158203)\n",
      "('sunny', 84.97631072998047)\n",
      "('cloudy', 62.22285842895508)\n"
     ]
    }
   ],
   "source": [
    "# So far what we have done have been independent of Pyro. We will now rewrite our weather function, such that it can\n",
    "# be used for something else than just sampling fake data.\n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "# Create a named pyro sample which we call \"my_sample\".\n",
    "# Pyro's backend uses the sample names to uniquely identify statements and change their behavior at runtime\n",
    "# depending on how the enclosing stochastic function is being used.\n",
    "x = pyro.sample(\"my_sample\", pyro.distributions.Normal(loc,scale))\n",
    "\n",
    "def weather():\n",
    "    # Create a Bernoulli distribution and sample from it, so our sample is either a 1 or 0\n",
    "    # 0.3 = 30% chance of a 1, and 70% chance of a 0\n",
    "    cloudy = pyro.sample(\"cloudy\", pyro.distributions.Bernoulli(0.3))\n",
    "    # If our sample is 1, then we say it was \"cloudy\", else it was \"sunny\"\n",
    "    cloudy = \"cloudy\" if cloudy.item() == 1.0 else \"sunny\"\n",
    "    \n",
    "    # Create a dicstrionary with the sky attributes as keys, and the values are the temperature\n",
    "    # At the same time, we acces a value by reffering to the key [cloudy]. This value is our temperature mean\n",
    "    # Note that cloudy days have a lower mean temperature\n",
    "    mean_temp = {\"cloudy\": 55.0, \"sunny\": 75.0}[cloudy]\n",
    "    \n",
    "    # Same as above, but this is our variance for the temperature\n",
    "    scale_temp = {\"cloudy\": 10.0, \"sunny\": 15.0}[cloudy]\n",
    "    \n",
    "    # Create a normal distribution for the temperature, giving it our mean and variance we calculated above\n",
    "    # We immidently sample from it\n",
    "    temp = pyro.sample(\"temp\", pyro.distributions.Normal(mean_temp, scale_temp))\n",
    "    \n",
    "    # Return sky attribute with the temperature\n",
    "    return cloudy, temp.item()\n",
    "    \n",
    "for i in range(0,10):\n",
    "    print(weather())\n",
    "    \n",
    "\n",
    "# Because the randomness is now invoked with pyro.sample, it now specifies a joint probability distribution two\n",
    "# named random variable: \"cloudy\" and temp. As such, it defines a probabillistic model that we can reason about\n",
    "# using the techniques of probability theory.\n",
    "\n",
    "# For example we might ask: if I observe a temperature of 70 degrees, how likely is it to be cloudy?\n",
    "# The next tutorial will cover hos to formulate and answer these questions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universality: Stochastic Recursion, Higher-order Stochastic Functions, and Random Control Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(51.0729)\n",
      "tensor(33.9623)\n",
      "tensor(51.3045)\n",
      "tensor(196.1405)\n",
      "tensor(183.7483)\n",
      "tensor(55.6039)\n",
      "tensor(50.4442)\n",
      "tensor(50.9286)\n",
      "tensor(65.0976)\n",
      "tensor(44.0715)\n"
     ]
    }
   ],
   "source": [
    "# Create a model for expected sales of ice creams, using our previous weather function.\n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "def ice_cream_sales():\n",
    "    # Getting the sky attribute and temperature for the day\n",
    "    cloudy, temp = weather()\n",
    "    # If it is sunny and above 80 degrees, then we expect to sell 4 times more ice cream than normal\n",
    "    expected_sales = 200 if cloudy == \"sunny\" and temp > 80.0 else 50\n",
    "    # Create a normal distribution for the sales of ice, with the expected sales as the mean and a variance of 10.\n",
    "    # Sample from it.\n",
    "    ice_cream = pyro.sample(\"ice_cream\", pyro.distributions.Normal(expected_sales, 10.0))\n",
    "    \n",
    "    # Return the sample of ice creams sold\n",
    "    return ice_cream\n",
    "\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(ice_cream_sales())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faliures before succes:  0\n"
     ]
    }
   ],
   "source": [
    "# We can construct recursive functions that terminate their recursion nondeterministically, provided we take care to \n",
    "# pass pyro.sample unique sample names whenever itâ€™s called.\n",
    "\n",
    "# Define a geometric distribution that counts the number of failures until the first succes.\n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "# Geometric distribution = The probability distribution of the number X of Bernoulli trials needed to get one success, \n",
    "# supported on the set { 1, 2, 3, ...}\n",
    "\n",
    "# p = probability of succes\n",
    "# t = trials\n",
    "def geometric(p, t=None):\n",
    "    if t is None:\n",
    "        t = 0\n",
    "    x = pyro.sample(\"x_{}\".format(t), pyro.distributions.Bernoulli(p))\n",
    "    if x.item() == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 + geometric(p, t + 1)\n",
    "    \n",
    "# Printing x gives e.g tensor(0.)\n",
    "# Printing x.item() gives normal float e.g 0.0\n",
    "\n",
    "print(\"Number of faliures before succes: \",geometric(0.5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5655)\n"
     ]
    }
   ],
   "source": [
    "# Example to show that a stochastic function can accept as input or produce as output other stochastic functions\n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "# Stochastic function\n",
    "def normal_product(loc, scale):\n",
    "    z1 = pyro.sample(\"z1\", pyro.distributions.Normal(loc, scale))\n",
    "    z2 = pyro.sample(\"z2\", pyro.distributions.Normal(loc, scale))\n",
    "    y = z1 * z2\n",
    "    return y\n",
    "\n",
    "# Another stochastic function that takes one argument and which upon execution, generates three named random variables\n",
    "def make_normal_normal():\n",
    "    mu_latent = pyro.sample(\"mu_latent\", pyro.distributions.Normal(0,1))\n",
    "    fn = lambda scale: normal_product(mu_latent, scale)\n",
    "    return fn\n",
    "\n",
    "\n",
    "# The (1.) is for the lambda expression\n",
    "print(make_normal_normal()(1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Inference in Pyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up the imports for the tutorial\n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import pyro\n",
    "import pyro.infer\n",
    "import pyro.optim\n",
    "import pyro.distributions as dist\n",
    "\n",
    "pyro.set_rng_seed(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You weigh:  57.99806594848633\n"
     ]
    }
   ],
   "source": [
    "# We want to figure out how much something weighs, but the scale is faulty. We will take this faultyness into account, by\n",
    "# adding noise to the measurement. The noise will be a guess based on some prior knowledge about the object, like its\n",
    "# density or material properties.\n",
    "\n",
    "# What is the weight given a guess, which we sample from a normal distribution.\n",
    "# Weight | guess ~ Normal(guess,1)   \n",
    "\n",
    "# What does the measurement give us, given our guess and weight, which we sample from a normal distribution.\n",
    "# Measurement | guess, weight ~ Normal(weight, 0.75)\n",
    "\n",
    "# The following stochastic function models the above:\n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "# We make a guess, but because it is a guess it is not precise, so we make a distribution with our guess as the mean\n",
    "# and with a variance of 1. This way we get a more \"even\" guess.\n",
    "# Our guess now called \"weight\" is used so make another normal distribution, which our scale will sample/measure from.\n",
    "def scale(guess):\n",
    "    weight = pyro.sample(\"weight\", dist.Normal(guess, 1.0))\n",
    "    return pyro.sample(\"measurement\", dist.Normal(weight,0.75))\n",
    "\n",
    "print(\"You weigh: \", scale(60).item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.5\n"
     ]
    }
   ],
   "source": [
    "# Let us look at scale again. This time, we have given the input 8.5 and gotten the output 9.5.\n",
    "# We now wish to sample from the distribution of weight given the above observation.\n",
    "# In other words, we want to infer the distribution:\n",
    "# (Weight | guess, measurement = 9.5) ~ ?\n",
    "\n",
    "# We can use the function pyro.condition to allow us to constrain the value of samples statements.\n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "# Pyro.condition takes a model and a dictionary of observations and returns a new model that has the same input \n",
    "# and output signatures but always uses the given values at observed sample statements.\n",
    "conditioned_scale = pyro.condition(scale, data={\"measurement\": 9.5})\n",
    "\n",
    "# Conditioning can be deferred or parametrized with Python's lambda or def.\n",
    "def deferred_conditioned_scale(measurement, *args, **kwargs):\n",
    "    return pyro.condition(scale, data={\"measurement\": measurement})(*args,**kwargs)\n",
    "\n",
    "print(deferred_conditioned_scale(9.5,8.5))\n",
    "\n",
    "# We can also just pass observations \n",
    "def scale_obs(guess):\n",
    "    weight = pyro.sample(\"weight\", dist.Normal(guess, 1.0))\n",
    "    \n",
    "    return pyro.sample(\"measurement\", dist.Normal(weight, 1.0), obs=9.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flexible Approximate Inference With Guide Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.122642517089844\n",
      "26.62798309326172\n",
      "28.041976928710938\n",
      "27.528827667236328\n",
      "27.41761016845703\n",
      "27.336336135864258\n",
      "25.758628845214844\n",
      "28.017961502075195\n",
      "27.80918312072754\n",
      "26.36229705810547\n"
     ]
    }
   ],
   "source": [
    "# For our scale example, we can calulate the posterior distribution to be Normal(9.14,0.6) by deriving it from the formulas\n",
    "# in 3.4 http://www.stat.cmu.edu/~brian/463-663/week09/Chapter%2003.pdf\n",
    "\n",
    "# The perfect model is therefore:\n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "def perfect_guide(guess):\n",
    "    loc = (0.75**2 * guess + 9.5) / (1 + 0.75**2) # 9.14\n",
    "    scale = np.sqrt(0.75**2/(1 + 0.75**2)) # 0.6\n",
    "    return pyro.sample(\"weight\", dist.Normal(loc,scale))\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(perfect_guide(60).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametrized Stochastic Functions and Variational Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using a non-linear function in the middle.\n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "def intractable_scale(guess):\n",
    "    weight = pyro.sample(\"weight\", dist.Normal(guess, 1.0))\n",
    "    return pyro.sample(\"measurement\", dist.Normal(some_nonlinear_function(weight), 0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example of \n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "simple_param_store ={}\n",
    "a = simple_param_store.setdefault(\"a\", torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "def scale_parametrized_guide(guess):\n",
    "    a = pyro.param(\"a\", torch.tensor(guess))\n",
    "    b = pyro.param(\"b\", torch.tensor(1.0))\n",
    "    return pyro.sample(\"weight\", dist.Normal(a, torch.abs(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Makin the same as above, but instead of ensuring our b is positive by doing abs(), we make a constraint instead\n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "from torch.distributions import constraints\n",
    "\n",
    "def scale_parametrized_guide_constrained(guess):\n",
    "    a = pyro.param(\"a\", torch.tensor(guess))\n",
    "    b = pyro.param(\"b\", torch.tensor(1.0), constraints=constraints.positive)\n",
    "    return pyro.sample(\"weight\",dist.Normal(a, b)) # No more torch.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hakan/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  0.6328046321868896\n",
      "b =  9.110170364379883\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "#___________________________________________________________________________________________________________________________\n",
    "\n",
    "guess = torch.tensor(8.5)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "svi = pyro.infer.SVI(model=conditioned_scale,\n",
    "                     guide=scale_parametrized_guide,\n",
    "                     optim=pyro.optim.SGD({\"lr\": 0.001, \"momentum\": 0.1}),\n",
    "                     loss=pyro.infer.Trace_ELBO())\n",
    "\n",
    "losses = []\n",
    "a = []\n",
    "b = []\n",
    "\n",
    "num_steps = 2500\n",
    "for t in range(num_steps):\n",
    "    losses.append(svi.step(guess))\n",
    "    a.append(pyro.param(\"a\").item())\n",
    "    b.append(pyro.param(\"b\").item())\n",
    "    \n",
    "    \n",
    "plt.plot(losses)\n",
    "plt.title(\"ELBO\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "print(\"a = \", pyro.param(\"b\").item())\n",
    "print(\"b = \", pyro.param(\"a\").item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.plot([0,num_steps],[9.14,9.14], 'k:')\n",
    "plt.plot(a)\n",
    "plt.ylabel('a')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.ylabel('b')\n",
    "plt.plot([0,num_steps],[0.6,0.6], 'k:')\n",
    "plt.plot(b)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#assert pyro.__version__.startswith('0.3.0')\n",
    "pyro.enable_validation(True)\n",
    "pyro.distributions.enable_validation(False)\n",
    "pyro.set_rng_seed(0)\n",
    "\n",
    "smoke_test = 'CI' in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_data_loader(batch_size=128, use_cuda=False):\n",
    "    root = './data'\n",
    "    download = True\n",
    "    trans = transforms.ToTensor()\n",
    "    \n",
    "    train_set = dset.MNIST(root=root, train=True, transformation=trans, download=download)\n",
    "    test_set = dset.MNIST(root=root, train=False, transform=trans)\n",
    "    \n",
    "    kwargs = {'num_workers': 1, 'pin_memory': use_cuda}\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
